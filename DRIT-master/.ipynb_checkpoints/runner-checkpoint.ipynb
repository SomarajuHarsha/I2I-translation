{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872e9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5ff206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Using cached tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\sriha\\anaconda3\\lib\\site-packages (from tensorboardX) (3.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sriha\\anaconda3\\lib\\site-packages (from tensorboardX) (1.20.2)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\sriha\\anaconda3\\lib\\site-packages (from protobuf>=3.8.0->tensorboardX) (1.16.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install future graphviz hypothesis protobuf pydot python-nvd3 pyyaml six tornado Pillow cython tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4ae698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- load options ---\n",
      "batch_size: 2\n",
      "concat: 1\n",
      "crop_size: 216\n",
      "d_iter: 3\n",
      "dataroot: ../../datasets/selfie2anime\n",
      "dis_norm: None\n",
      "dis_scale: 3\n",
      "dis_spectral_norm: False\n",
      "display_dir: ../selfie2anime/logs\n",
      "display_freq: 1\n",
      "gpu: 0\n",
      "img_save_freq: 5\n",
      "input_dim_a: 3\n",
      "input_dim_b: 3\n",
      "lr_policy: lambda\n",
      "model_save_freq: 10\n",
      "nThreads: 8\n",
      "n_ep: 1200\n",
      "n_ep_decay: 600\n",
      "name: selfie2anime\n",
      "no_display_img: False\n",
      "no_flip: False\n",
      "no_ms: False\n",
      "phase: train\n",
      "resize_size: 256\n",
      "result_dir: ../selfie2anime/results\n",
      "resume: None\n",
      "\n",
      "--- load dataset ---\n",
      "A: 3400, B: 3400 images\n",
      "\n",
      "--- load model ---\n",
      "start the training at epoch 0\n",
      "\n",
      "--- train ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriha\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 78, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 51, in main\n",
      "    model.update_D(images_a, images_b)\n",
      "  File \"C:\\Users\\sriha\\OneDrive\\Desktop\\Research\\I2I translation\\DRIT-master\\src\\model.py\", line 220, in update_D\n",
      "    self.forward()\n",
      "  File \"C:\\Users\\sriha\\OneDrive\\Desktop\\Research\\I2I translation\\DRIT-master\\src\\model.py\", line 155, in forward\n",
      "    output_fakeA = self.gen.forward_a(input_content_forA, input_attr_forA)\n",
      "  File \"C:\\Users\\sriha\\OneDrive\\Desktop\\Research\\I2I translation\\DRIT-master\\src\\networks.py\", line 381, in forward_a\n",
      "    out3 = self.decA3(x_and_z3)\n",
      "  File \"C:\\Users\\sriha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\sriha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\sriha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\sriha\\OneDrive\\Desktop\\Research\\I2I translation\\DRIT-master\\src\\networks.py\", line 611, in forward\n",
      "    return self.model(x)\n",
      "  File \"C:\\Users\\sriha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\sriha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\sriha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\sriha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 907, in forward\n",
      "    output_padding, self.groups, self.dilation)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 2.00 GiB total capacity; 1.14 GiB already allocated; 0 bytes free; 1.25 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot ../../datasets/selfie2anime --name selfie2anime --display_dir ../selfie2anime/logs --result_dir ../selfie2anime/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b601e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
